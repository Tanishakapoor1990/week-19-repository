{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8702ab1",
   "metadata": {},
   "source": [
    "Take one of the supervised learning models you have built recently and apply at least\n",
    "three dimensionality reduction techniques to it (separately). Be sure to create a short\n",
    "summary of each technique you use. Indicate how each changed the model\n",
    "performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf4e9e8",
   "metadata": {},
   "source": [
    "## I'm using Australian credit dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d328531d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>22.08</td>\n",
       "      <td>11.460</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.585</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1213</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>22.67</td>\n",
       "      <td>7.000</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>29.58</td>\n",
       "      <td>1.750</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>280</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>21.67</td>\n",
       "      <td>11.500</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.17</td>\n",
       "      <td>8.170</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1.960</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>1</td>\n",
       "      <td>31.57</td>\n",
       "      <td>10.500</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>6.500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>1</td>\n",
       "      <td>20.67</td>\n",
       "      <td>0.415</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>0</td>\n",
       "      <td>18.83</td>\n",
       "      <td>9.540</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.085</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>0</td>\n",
       "      <td>27.42</td>\n",
       "      <td>14.500</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>3.085</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>1</td>\n",
       "      <td>41.00</td>\n",
       "      <td>0.040</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>560</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>690 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     A1     A2      A3  A4  A5  A6     A7  A8  A9  A10  A11  A12  A13   A14  \\\n",
       "0     1  22.08  11.460   2   4   4  1.585   0   0    0    1    2  100  1213   \n",
       "1     0  22.67   7.000   2   8   4  0.165   0   0    0    0    2  160     1   \n",
       "2     0  29.58   1.750   1   4   4  1.250   0   0    0    1    2  280     1   \n",
       "3     0  21.67  11.500   1   5   3  0.000   1   1   11    1    2    0     1   \n",
       "4     1  20.17   8.170   2   6   4  1.960   1   1   14    0    2   60   159   \n",
       "..   ..    ...     ...  ..  ..  ..    ...  ..  ..  ...  ...  ...  ...   ...   \n",
       "685   1  31.57  10.500   2  14   4  6.500   1   0    0    0    2    0     1   \n",
       "686   1  20.67   0.415   2   8   4  0.125   0   0    0    0    2    0    45   \n",
       "687   0  18.83   9.540   2   6   4  0.085   1   0    0    0    2  100     1   \n",
       "688   0  27.42  14.500   2  14   8  3.085   1   1    1    0    2  120    12   \n",
       "689   1  41.00   0.040   2  10   4  0.040   0   1    1    0    1  560     1   \n",
       "\n",
       "     Target  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         1  \n",
       "4         1  \n",
       "..      ...  \n",
       "685       1  \n",
       "686       0  \n",
       "687       1  \n",
       "688       1  \n",
       "689       1  \n",
       "\n",
       "[690 rows x 15 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "credit_df = pd.read_csv('../week-16-repository/Australian.CSV',names=['A1','A2','A3','A4','A5','A6','A7','A8','A9','A10','A11','A12','A13','A14','Target'])\n",
    "credit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c3a46a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.68873723 0.80105183 1.34711063 ... 0.48835847 0.03738039 0.89530251]\n",
      " [1.45193254 0.75124044 0.45054795 ... 0.13959116 0.19541334 0.89530251]\n",
      " [1.45193254 0.16785619 0.60482292 ... 0.55794344 0.19541334 0.89530251]\n",
      " ...\n",
      " [1.45193254 1.07543661 0.96114643 ... 0.48835847 0.19541334 1.11694091]\n",
      " [1.45193254 0.35021653 1.95822062 ... 0.3721027  0.19330052 1.11694091]\n",
      " [0.68873723 0.79628971 0.94857229 ... 2.18552419 0.19541334 1.11694091]]\n"
     ]
    }
   ],
   "source": [
    "#Removing outliers using z-score\n",
    "#Some columns are observed to have outliers \n",
    "\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "z = np.abs(stats.zscore(credit_df))\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3d73c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 27,  34,  35,  36,  39,  63,  63,  70,  74,  74,  78,  84,  85,\n",
      "        90, 114, 119, 121, 133, 143, 143, 145, 146, 146, 146, 148, 149,\n",
      "       150, 155, 165, 170, 177, 179, 182, 183, 185, 186, 193, 195, 196,\n",
      "       199, 202, 204, 216, 225, 228, 233, 233, 233, 237, 237, 239, 239,\n",
      "       243, 247, 258, 267, 271, 277, 279, 282, 286, 287, 290, 293, 316,\n",
      "       316, 322, 331, 344, 351, 356, 360, 360, 363, 364, 366, 374, 374,\n",
      "       375, 390, 394, 415, 434, 448, 452, 452, 471, 476, 482, 484, 486,\n",
      "       489, 498, 500, 500, 500, 508, 517, 531, 532, 538, 547, 549, 558,\n",
      "       559, 559, 564, 564, 568, 569, 579, 586, 586, 596, 606, 613, 632,\n",
      "       639, 641, 642, 643, 645, 654, 654, 661, 669, 677, 680, 689],\n",
      "      dtype=int64), array([13,  6,  1, 11,  6, 11, 12,  2,  2,  6, 11, 11, 11, 11, 11,  6, 11,\n",
      "       11,  2,  6,  1,  1,  2,  6,  6, 13, 11, 11, 11, 11, 11,  6,  9, 11,\n",
      "       11, 11, 11,  9, 13, 12, 13,  9, 11, 11,  6,  2,  6,  9,  1, 11,  6,\n",
      "       11,  1,  6, 11, 13, 11, 11,  2, 11,  6,  6, 11, 12,  6, 12,  6, 11,\n",
      "       11, 12, 11,  1,  6, 12, 11, 11, 11, 12,  2,  1, 11, 11,  9, 11,  1,\n",
      "       11,  6, 11, 11, 11,  6, 11, 11,  2, 11, 13, 11, 11, 11, 11,  6, 11,\n",
      "       11,  1,  6,  9,  6,  9, 11, 11, 11,  2, 12, 11, 11, 11, 11, 11,  9,\n",
      "        2, 11, 11, 11, 12, 11, 11, 11, 11, 11], dtype=int64))\n",
      "3.2671052811360295\n"
     ]
    }
   ],
   "source": [
    "#The first array contains the list of row numbers and second\n",
    "#array respective column numbers, which mean z[27][13] have a Z-score higher than 3.\n",
    "\n",
    "threshold = 3\n",
    "print(np.where(z > 3))\n",
    "print(z[27][13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2619b74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_df = credit_df[(z < 3).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cee588f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>22.08</td>\n",
       "      <td>11.460</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.585</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1213</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>22.67</td>\n",
       "      <td>7.000</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>29.58</td>\n",
       "      <td>1.750</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>280</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>21.67</td>\n",
       "      <td>11.500</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.17</td>\n",
       "      <td>8.170</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1.960</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>1</td>\n",
       "      <td>43.00</td>\n",
       "      <td>0.290</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>1.750</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>376</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>1</td>\n",
       "      <td>31.57</td>\n",
       "      <td>10.500</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>6.500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>1</td>\n",
       "      <td>20.67</td>\n",
       "      <td>0.415</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>0</td>\n",
       "      <td>18.83</td>\n",
       "      <td>9.540</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.085</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>0</td>\n",
       "      <td>27.42</td>\n",
       "      <td>14.500</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>3.085</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>580 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     A1     A2      A3  A4  A5  A6     A7  A8  A9  A10  A11  A12  A13   A14  \\\n",
       "0     1  22.08  11.460   2   4   4  1.585   0   0    0    1    2  100  1213   \n",
       "1     0  22.67   7.000   2   8   4  0.165   0   0    0    0    2  160     1   \n",
       "2     0  29.58   1.750   1   4   4  1.250   0   0    0    1    2  280     1   \n",
       "3     0  21.67  11.500   1   5   3  0.000   1   1   11    1    2    0     1   \n",
       "4     1  20.17   8.170   2   6   4  1.960   1   1   14    0    2   60   159   \n",
       "..   ..    ...     ...  ..  ..  ..    ...  ..  ..  ...  ...  ...  ...   ...   \n",
       "684   1  43.00   0.290   1  13   8  1.750   1   1    8    0    2  100   376   \n",
       "685   1  31.57  10.500   2  14   4  6.500   1   0    0    0    2    0     1   \n",
       "686   1  20.67   0.415   2   8   4  0.125   0   0    0    0    2    0    45   \n",
       "687   0  18.83   9.540   2   6   4  0.085   1   0    0    0    2  100     1   \n",
       "688   0  27.42  14.500   2  14   8  3.085   1   1    1    0    2  120    12   \n",
       "\n",
       "     Target  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         1  \n",
       "4         1  \n",
       "..      ...  \n",
       "684       1  \n",
       "685       1  \n",
       "686       0  \n",
       "687       1  \n",
       "688       1  \n",
       "\n",
       "[580 rows x 15 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Outliers have been removed from this dataset\n",
    "credit_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4a0f89",
   "metadata": {},
   "source": [
    "## Building baseline logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c097e7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 0 1 1 1 0 1 0 0 1 0 1 0 0 0 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 0 0 1 1 1\n",
      " 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 1 1 0 0 1 1 0 1 1\n",
      " 0 0 1 0 1 1 1 0 1 1 0 1 1 0 0 0 0 1 0 1 1 1 1 1 1 1 1 0 0 0 0 0 1 0 1 0 1\n",
      " 1 1 1 0 0]\n",
      "test accuracy: 0.8448275862068966\n",
      "train accuracy: 0.9073275862068966\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Defining X and y \n",
    "X = credit_df.drop('Target',axis=1)\n",
    "y = credit_df['Target']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=42,test_size=0.2)\n",
    "\n",
    "#Standardize\n",
    "sc= StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.fit_transform(X_test)\n",
    "\n",
    "# Logistic Regression\n",
    "clr = LogisticRegression(random_state=42)\n",
    "clr.fit(X_train,y_train)\n",
    "#predict\n",
    "y_predicted= clr.predict(X_test)\n",
    "print(y_predicted)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"test accuracy: \" + str(clr.score(X_test, y_test)))\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"train accuracy: \" + str(clr.score(X_train, y_train)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fc3f55",
   "metadata": {},
   "source": [
    "## Using SVD "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b063f45e",
   "metadata": {},
   "source": [
    "Singular Value Decomposition (SVD) is a common dimensionality \n",
    "reduction technique in data science. We use TruncatedSVD from sklearn.decomposition.\n",
    "You specify the number of features you want in the output as the n_components parameter. \n",
    "n_components should be strictly less than the number of features in \n",
    "the input matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "72b49191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8599137931034483\n",
      "0.8448275862068966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sunny\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\sunny\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Defining X and y \n",
    "X = credit_df.drop('Target',axis=1)\n",
    "y = credit_df['Target']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=42,test_size=0.2)\n",
    "\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "svd = TruncatedSVD(n_components=13)\n",
    "X_train_svd=svd.fit_transform(X_train)\n",
    "X_test_svd=svd.fit_transform(X_test)\n",
    "\n",
    "clr = LogisticRegression(random_state=42).fit(X_train_svd, y_train)\n",
    "print(clr.score(X_train_svd,y_train))\n",
    "\n",
    "clr = LogisticRegression(random_state=42).fit(X_test_svd, y_test)\n",
    "print(clr.score(X_test_svd,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabc6f1b",
   "metadata": {},
   "source": [
    "If we compare it to the baseline model we can say that SVD test performance is almost same around 84.48% whereas training performance has decreased to 85%.\n",
    "\n",
    "I think after applying SVD we are able to make our model much better as  the baseline logistic regression model was too overfitted.  After applying SVD train and test accuracies are closer so we can say that it no more an overfitted model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1b2b7b",
   "metadata": {},
   "source": [
    "Applying PCA "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7acd42f",
   "metadata": {},
   "source": [
    "Principal component analysis is a statistical technique to convert high dimensional data to low dimensional \n",
    "data by selecting the most important features that capture maximum information about the dataset. \n",
    "The features are selected on the basis of variance that they cause in the output. The feature that causes \n",
    "highest variance is the first principal component. The feature that is responsible for second highest variance \n",
    "is considered the second principal component, and so on. It is important to mention that principal components do \n",
    "not have any correlation with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "90e7d74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8426724137931034\n",
      "0.8275862068965517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sunny\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\sunny\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#Defining X and y \n",
    "X = credit_df.drop('Target',axis=1)\n",
    "y = credit_df['Target']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=42,test_size=0.2)\n",
    "\n",
    "\n",
    "pca = PCA(n_components=11)\n",
    "X_train_pca=pca.fit_transform(X_train)\n",
    "X_test_pca=pca.fit_transform(X_test)\n",
    "\n",
    "clr = LogisticRegression(random_state=42).fit(X_train_pca, y_train)\n",
    "print(clr.score(X_train_pca,y_train))\n",
    "\n",
    "clr = LogisticRegression(random_state=42).fit(X_test_pca, y_test)\n",
    "print(clr.score(X_test_pca,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26c0a82",
   "metadata": {},
   "source": [
    "I think after applying PCA  we are able to make our model much better as the baseline logistic regression model was too overfitted. \n",
    "After applying PCA  train and test accuracies are closer so we can say that it no more an overfitted model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9420a5dc",
   "metadata": {},
   "source": [
    "## Isometric Mapping (Isomap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c49139",
   "metadata": {},
   "source": [
    "Isomap stands for isometric mapping. Isomap is a non-linear dimensionality reduction method .\n",
    "It can be thought of as an extension of Multi-Dimensional Scaling(MDS) or Kernel PCA.\n",
    "It tries to find lower dimensional embedding of the original dataset while maintaining geodesic distances \n",
    "between all points in the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8c136343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6702586206896551\n",
      "0.7155172413793104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sunny\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\sunny\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn import manifold\n",
    "#Defining X and y \n",
    "X = credit_df.drop('Target',axis=1)\n",
    "y = credit_df['Target']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=42,test_size=0.2)\n",
    "\n",
    "iso = manifold.Isomap(n_neighbors=20, n_components=12)\n",
    "X_train_iso=iso.fit_transform(X_train)\n",
    "X_test_iso=iso.fit_transform(X_test)\n",
    "\n",
    "clr = LogisticRegression(random_state=42).fit(X_train_iso, y_train)\n",
    "print(clr.score(X_train_iso,y_train))\n",
    "\n",
    "clr = LogisticRegression(random_state=42).fit(X_test_iso, y_test)\n",
    "print(clr.score(X_test_iso,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a03aa22",
   "metadata": {},
   "source": [
    "In this case, I don’t see any lift in model performance while using the Isometric Mapping (Isomap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f92f6e",
   "metadata": {},
   "source": [
    "2) Write a function that will indicate if an inputted IPv4 address is accurate or not.\n",
    "IP addresses are valid if they have 4 values between 0 and 255 (inclusive), punctuated\n",
    "by periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "20d4aa19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true\n",
      "false\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import re   # for regular expressions\n",
    "# Make a regular expression\n",
    "# for validating an Ip-address\n",
    "regex = \"^((25[0-5]|2[0-4][0-9]|1[0-9][0-9]|[1-9]?[0-9])\\.){3}(25[0-5]|2[0-4][0-9]|1[0-9][0-9]|[1-9]?[0-9])$\"\n",
    "\n",
    "# Define a function \n",
    "def check(Ip):\n",
    "    # pass the regular expression\n",
    "    # and the string in search() method\n",
    "    if(re.search(regex, Ip)):\n",
    "        print(\"true\")\n",
    "    else:\n",
    "        print(\"false\")\n",
    "# Driver Code\n",
    "if __name__ == '__main__' :\n",
    "    # Enter the Ip address\n",
    "    Ip = \"2.33.245.5\"\n",
    "    # calling run function\n",
    "    check(Ip)\n",
    "    Ip = \"12.345.67.89\"\n",
    "    check(Ip)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730441ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
